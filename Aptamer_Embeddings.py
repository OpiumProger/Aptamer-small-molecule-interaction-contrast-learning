import pandas as pd
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForMaskedLM
from tqdm import tqdm



def simple_gena_encode(csv_file, sequence_column='aptamer', output_file='embeddings.csv'):

    tokenizer = AutoTokenizer.from_pretrained('AIRI-Institute/gena-lm-bert-base')

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º AutoModelForMaskedLM
    model = AutoModelForMaskedLM.from_pretrained(
        'AIRI-Institute/gena-lm-bert-base',
        trust_remote_code=True,
        output_hidden_states=True
    )
    model.eval()

    df = pd.read_csv(csv_file)

    if sequence_column not in df.columns:
        print(f"–ö–æ–ª–æ–Ω–∫–∞ '{sequence_column}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Ñ–∞–π–ª–µ!")
        print(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
        return None

    # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    sequences = df[sequence_column].tolist()

    # –û—á–∏—â–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    clean_sequences = []
    clean_indices = []

    print(" –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π...")
    for idx, seq in enumerate(sequences):
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN
        if pd.isna(seq):
            print(f" –ü—Ä–æ–ø—É—Å–∫ —Å—Ç—Ä–æ–∫–∏ {idx}: NaN –∑–Ω–∞—á–µ–Ω–∏–µ")
            continue

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–∞ –¥–∞–Ω–Ω—ã—Ö
        if not isinstance(seq, str):
            print(f" –ü—Ä–æ–ø—É—Å–∫ —Å—Ç—Ä–æ–∫–∏ {idx}: –Ω–µ —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (—Ç–∏–ø: {type(seq).__name__})")
            continue

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
        seq = str(seq).strip()
        if not seq:
            print(f" –ü—Ä–æ–ø—É—Å–∫ —Å—Ç—Ä–æ–∫–∏ {idx}: –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞")
            continue

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã
        if len(seq) < 3:
            print(f" –ü—Ä–æ–ø—É—Å–∫ —Å—Ç—Ä–æ–∫–∏ {idx}: —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å ({len(seq)} —Å–∏–º–≤–æ–ª–æ–≤)")
            continue

        clean_sequences.append(seq)
        clean_indices.append(idx)

    print(f"    –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π: {len(sequences)}")
    print(f"    –û—á–∏—â–µ–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π: {len(clean_sequences)}")
    print(f"    –£–¥–∞–ª–µ–Ω–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π: {len(sequences) - len(clean_sequences)}")

    if len(clean_sequences) == 0:
        print(" –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏!")
        return None

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    max_length = 32
    batch_size = 16
    all_embeddings = []

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞–º–∏
    print(" –ù–∞—á–∏–Ω–∞–µ–º –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ...")
    for i in tqdm(range(0, len(clean_sequences), batch_size), desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–µ–π"):
        batch = clean_sequences[i:i + batch_size]

        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º U -> T
            batch = [seq.upper().replace('U', 'T') for seq in batch]

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
            for j, seq in enumerate(batch):
                if not all(c in 'ATCGN' for c in seq):
                    print(f" –ë–∞—Ç—á {i}, –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å {j}: —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã: {seq}")

            # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
            inputs = tokenizer(
                batch,
                return_tensors="pt",
                padding=True,
                truncation=True,
                max_length=max_length
            )

            # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—ã—Ö–æ–¥–æ–≤ —Å hidden_states
            with torch.no_grad():
                outputs = model(**inputs, output_hidden_states=True)

            last_hidden_state = outputs.hidden_states[-1]

            # –£—Å—Ä–µ–¥–Ω—è–µ–º –ø–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            attention_mask = inputs['attention_mask'].unsqueeze(-1)
            sum_emb = (last_hidden_state * attention_mask).sum(dim=1)
            sum_mask = attention_mask.sum(dim=1)
            embeddings = sum_emb / sum_mask

            all_embeddings.append(embeddings.numpy())

        except Exception as e:
            print(f"   –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –±–∞—Ç—á–∞ {i}-{i + batch_size}: {e}")
            print(f"   –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {len(batch)}")
            print(f"   –ü—Ä–∏–º–µ—Ä –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {batch[0] if batch else '–Ω–µ—Ç'}")
            continue

    if len(all_embeddings) == 0:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏!")
        return None

    all_embeddings = np.vstack(all_embeddings)

    print(f" –ü–æ–ª—É—á–µ–Ω–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {all_embeddings.shape}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN –≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞—Ö
    nan_count = np.isnan(all_embeddings).sum()
    if nan_count > 0:
        print(f" –í —ç–º–±–µ–¥–¥–∏–Ω–≥–∞—Ö –Ω–∞–π–¥–µ–Ω–æ {nan_count} NaN –∑–Ω–∞—á–µ–Ω–∏–π")
        # –ó–∞–º–µ–Ω—è–µ–º NaN –Ω–∞ 0
        all_embeddings = np.nan_to_num(all_embeddings, nan=0.0)
        print(" NaN –∑–Ω–∞—á–µ–Ω–∏—è –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–∞ 0")


    inf_count = np.isinf(all_embeddings).sum()
    if inf_count > 0:
        print(f" –í —ç–º–±–µ–¥–¥–∏–Ω–≥–∞—Ö –Ω–∞–π–¥–µ–Ω–æ {inf_count} inf –∑–Ω–∞—á–µ–Ω–∏–π")
        # –ó–∞–º–µ–Ω—è–µ–º inf –Ω–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ/–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        all_embeddings = np.where(np.isinf(all_embeddings), 0.0, all_embeddings)
        print(" Inf –∑–Ω–∞—á–µ–Ω–∏—è –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–∞ 0")

    # –°–æ–∑–¥–∞–µ–º DataFrame —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏
    embed_df = pd.DataFrame(all_embeddings)
    embed_df.columns = [f'emb_{i}' for i in range(all_embeddings.shape[1])]

    embed_df['original_index'] = clean_indices[:len(embed_df)]

    # –°–æ–∑–¥–∞–µ–º DataFrame —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏ –∏–Ω–¥–µ–∫—Å–æ–º
    original_df = df.copy()
    original_df['original_index'] = original_df.index

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –ø–æ –∏–Ω–¥–µ–∫—Å—É
    result_df = pd.merge(original_df, embed_df, on='original_index', how='left')

    # –£–¥–∞–ª—è–µ–º –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—É—é –∫–æ–ª–æ–Ω–∫—É
    result_df = result_df.drop('original_index', axis=1)

    rows_with_emb = result_df[[f'emb_{i}' for i in range(all_embeddings.shape[1])]].notna().all(axis=1).sum()
    print(f"–°—Ç—Ä–æ–∫ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏: {rows_with_emb} –∏–∑ {len(result_df)}")

    result_df.to_csv(output_file, index=False)

    print(f"–ì–æ—Ç–æ–≤–æ! –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {output_file}")
    print(f"–†–∞–∑–º–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {all_embeddings.shape}")
    print(f"–†–∞–∑–º–µ—Ä –∏—Ç–æ–≥–æ–≤–æ–≥–æ DataFrame: {result_df.shape}")

    return result_df


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ CSV —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
def check_csv_file(csv_file, sequence_column='aptamer'):

    print(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞: {csv_file}")

    try:
        df = pd.read_csv(csv_file)
        print(f"–§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω. –†–∞–∑–º–µ—Ä: {df.shape}")
        print(f"–ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")

        if sequence_column not in df.columns:
            print(f"–ö–æ–ª–æ–Ω–∫–∞ '{sequence_column}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
            return None

        sequences = df[sequence_column]

        print("\n  –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –≤ –∫–æ–ª–æ–Ω–∫–µ '{}':".format(sequence_column))
        print(f"   –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {len(sequences)}")
        print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {sequences.nunique()}")
        print(f"   –ü—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (NaN): {sequences.isna().sum()}")
        print(f"   –ù–µ —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {(sequences.apply(type) != str).sum()}")

        # –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å—Ç—Ä–æ–∫
        print("\n –ü—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö:")
        for i in range(min(5, len(sequences))):
            val = sequences.iloc[i]
            print(f"   –°—Ç—Ä–æ–∫–∞ {i}: '{val}' (—Ç–∏–ø: {type(val).__name__})")

        # –ò—â–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
        print("\n–ü—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏:")
        problem_count = 0
        for idx, val in enumerate(sequences):
            if pd.isna(val):
                print(f"   –°—Ç—Ä–æ–∫–∞ {idx}: NaN")
                problem_count += 1
            elif not isinstance(val, str):
                print(f"   –°—Ç—Ä–æ–∫–∞ {idx}: –Ω–µ —Å—Ç—Ä–æ–∫–∞ ({type(val).__name__}): {val}")
                problem_count += 1
            elif not val.strip():
                print(f"   –°—Ç—Ä–æ–∫–∞ {idx}: –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞")
                problem_count += 1

        if problem_count == 0:
            print("–ü—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
        else:
            print(f"–ù–∞–π–¥–µ–Ω–æ {problem_count} –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å—Ç—Ä–æ–∫")

        return df

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        return None


if __name__ == "__main__":
    csv_file = "AptaBench_dataset_v2.csv"
    sequence_column = "sequence"
    df_checked = check_csv_file(csv_file, sequence_column)

    if df_checked is not None:

        # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
        result = simple_gena_encode(
            csv_file=csv_file,
            sequence_column=sequence_column,
            output_file="rna_pos_embeddings.csv"
        )

        if result is not None:
            print(f"–ò—Å—Ö–æ–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫: {len(df_checked)}")
            print(f"–†–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∏—Ö —Å—Ç—Ä–æ–∫: {len(result)}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            emb_columns = [col for col in result.columns if col.startswith('emb_')]
            if emb_columns:
                print(f"–ö–æ–ª–æ–Ω–æ–∫ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏: {len(emb_columns)}")
                print(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {len(emb_columns)}")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
                print("\n–ü–µ—Ä–≤—ã–µ 5 —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (–ø–µ—Ä–≤—ã–µ 5 –∑–Ω–∞—á–µ–Ω–∏–π):")
                for i in range(min(5, len(result))):
                    emb_sample = result[emb_columns].iloc[i].values[:5]
                    print(f"   –°—Ç—Ä–æ–∫–∞ {i}: {emb_sample}")
    else:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–∞–π–ª. –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ.")